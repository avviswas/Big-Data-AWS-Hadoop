As i have used Redhat we have to first install java
1. sudo yum install java-1.8.0-openjdk*
2. sudo yum install nano
3. sudo install wget
4. sudo wget http://apache.mirrors.ionfish.org/hadoop/common/hadoop-2.9.1/hadoop-2.9.1.tar.gz
5. tar xzvf hadoop-2.9.1.tar.gz
6. sudo nano /etc/hosts
		Instert public ip of master and slave
7.make changes into following files
	sudo nano /usr/local/hadoop-2.9.1/etc/hadoop core-site.xml
	sudo nano /usr/local/hadoop-2.9.1/etc/hadoop hdfs-site.xml
	sudo nano /usr/local/hadoop-2.9.1/etc/hadoop mapred-site.xml.template
	sudo nano /usr/local/hadoop-2.9.1/etc/hadoop yarn-site.xml
8. Perform these steps on Master
	ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa
	cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
	chmod 0600 ~/.ssh/authorized_keys
9. Perform these steps on Slave
	cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
	chmod 0600 ~/.ssh/authorized_keys
10. Use a file transfer software to copy files from master to slave
11. Execution for Pseduo distributed mode:
Execution:
	cd/usr/local/hadoop-2.9.1/bin/hdfs namenode -format
	cd/usr/local/hadoop-2.9.1/sbin/start-dfs.sh
	cd/usr/local/hadoop-2.9.1/bin/hdfs dfs -mkdir /user
    cd/usr/local/hadoop-2.9.1/bin/hdfs dfs -mkdir /user/ec2-user
	cd/usr/local/hadoop-2.9.1/bin/hdfs dfs -put 100KWikiText.txt
Build the file, create the jar and execute
12. Execution for full distributed mode is similar except we have to execute start-yarn.sh